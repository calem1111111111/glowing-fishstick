{
  "input": {
    "workflow": {
      "71": {
        "inputs": {
          "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
          "type": "wan",
          "device": "default"
        },
        "class_type": "CLIPLoader"
      },
      "72": {
        "inputs": {
          "text": "bad quality, blurry, watermark",
          "clip": ["71", 0]
        },
        "class_type": "CLIPTextEncode"
      },
      "73": {
        "inputs": {
          "vae_name": "wan_2.1_vae.safetensors"
        },
        "class_type": "VAELoader"
      },
      "74": {
        "inputs": {
          "width": 640,
          "height": 640,
          "length": 81,
          "batch_size": 1
        },
        "class_type": "EmptyHunyuanLatentVideo"
      },
      "75": {
        "inputs": {
          "unet_name": "wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors",
          "weight_dtype": "default"
        },
        "class_type": "UNETLoader"
      },
      "76": {
        "inputs": {
          "unet_name": "wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors",
          "weight_dtype": "default"
        },
        "class_type": "UNETLoader"
      },
      "78": {
        "inputs": {
          "add_noise": "disable",
          "noise_seed": 0,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "start_at_step": 2,
          "end_at_step": 4,
          "return_with_leftover_noise": "disable",
          "model": ["86", 0],
          "positive": ["89", 0],
          "negative": ["72", 0],
          "latent_image": ["81", 0]
        },
        "class_type": "KSamplerAdvanced"
      },
      "80": {
        "inputs": {
          "filename_prefix": "video/ComfyUI",
          "format": "auto",
          "codec": "auto",
          "video": ["88", 0]
        },
        "class_type": "SaveVideo"
      },
      "81": {
        "inputs": {
          "add_noise": "enable",
          "noise_seed": 392459563371087,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "simple",
          "start_at_step": 0,
          "end_at_step": 2,
          "return_with_leftover_noise": "enable",
          "model": ["82", 0],
          "positive": ["89", 0],
          "negative": ["72", 0],
          "latent_image": ["74", 0]
        },
        "class_type": "KSamplerAdvanced"
      },
      "82": {
        "inputs": {
          "shift": 5.0,
          "model": ["83", 0]
        },
        "class_type": "ModelSamplingSD3"
      },
      "83": {
        "inputs": {
          "lora_name": "wan2.2_t2v_lightx2v_4steps_lora_v1.1_high_noise.safetensors",
          "strength_model": 1.0,
          "model": ["75", 0]
        },
        "class_type": "LoraLoaderModelOnly"
      },
      "85": {
        "inputs": {
          "lora_name": "wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise.safetensors",
          "strength_model": 1.0,
          "model": ["76", 0]
        },
        "class_type": "LoraLoaderModelOnly"
      },
      "86": {
        "inputs": {
          "shift": 5.0,
          "model": ["85", 0]
        },
        "class_type": "ModelSamplingSD3"
      },
      "87": {
        "inputs": {
          "samples": ["78", 0],
          "vae": ["73", 0]
        },
        "class_type": "VAEDecode"
      },
      "88": {
        "inputs": {
          "fps": 16,
          "images": ["87", 0]
        },
        "class_type": "CreateVideo"
      },
      "89": {
        "inputs": {
          "text": "Beautiful young woman with flowing hair, gentle smile, cinematic slow-motion portrait, soft natural lighting",
          "clip": ["71", 0]
        },
        "class_type": "CLIPTextEncode"
      }
    }
  }
}
